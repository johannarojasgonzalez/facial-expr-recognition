{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jrojasgon/facial-expr-recognition/blob/master/FER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUgqytvVZEVQ",
        "colab_type": "code",
        "outputId": "460020c7-bfc8-4cf1-dd97-a00fef019b7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chjD1CdgZVtC",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "#@title Default title text\n",
        "from __future__ import print_function, division\n",
        "from builtins import range\n",
        "# Note: you may need to update your version of future\n",
        "# sudo pip install -U future\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def getData():\n",
        "    # images are 48x48 = 2304 size vectors\n",
        "    Y = []\n",
        "    X = []\n",
        "    first = True\n",
        "    for line in open('/content/drive/My Drive/Colab Notebooks/FER/fer2013.csv'):\n",
        "        if first:\n",
        "            first = False\n",
        "        else:\n",
        "            row = line.split(',')\n",
        "            Y.append(int(row[0]))\n",
        "            X.append([int(p) for p in row[1].split()])\n",
        "\n",
        "    X, Y = np.array(X) / 255.0, np.array(Y)\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "\n",
        "def getImageData():\n",
        "    X, Y = getData()\n",
        "    N, D = X.shape\n",
        "    d = int(np.sqrt(D))\n",
        "    print(d)\n",
        "    X = X.reshape(N, 1, d, d)\n",
        "    return X, Y\n",
        "  \n",
        "def y2indicator(y):\n",
        "    N = len(y)\n",
        "    K = len(set(y))\n",
        "    ind = np.zeros((N, K))\n",
        "    for i in range(N):\n",
        "        ind[i, y[i]] = 1\n",
        "    return ind\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdacfzUwc4mZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division\n",
        "from builtins import range, input\n",
        "# Note: you may need to update your version of future\n",
        "# sudo pip install -U future\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "label_map = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
        "\n",
        "def main():\n",
        "    X, Y = getData()\n",
        "\n",
        "    while True:\n",
        "        for i in range(7):\n",
        "            x, y = X[Y==i], Y[Y==i]\n",
        "            N = len(y)\n",
        "            j = np.random.choice(N)\n",
        "            plt.imshow(x[j].reshape(48, 48), cmap='gray')\n",
        "            plt.title(label_map[y[j]])\n",
        "            plt.show()\n",
        "        prompt = input('Quit? Enter Y:\\n')\n",
        "        if prompt == 'Y':\n",
        "            break\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUoQ6lY1d1by",
        "colab_type": "code",
        "outputId": "1ab53c52-6289-410c-e130-96405abce2b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1564
        }
      },
      "source": [
        "  from sklearn.utils import shuffle\n",
        "\n",
        "  # make a validation set\n",
        "  X, Y = getImageData()\n",
        "  # reshape X for tf: N x w x h x c\n",
        "  X = X.transpose((0, 2, 3, 1))\n",
        "  \n",
        "  X, Y = shuffle(X, Y)\n",
        "  X = X.astype(np.float32)\n",
        "  Y = y2indicator(Y).astype(np.float32)\n",
        "\n",
        "  Xvalid, Yvalid = X[-1000:], Y[-1000:]\n",
        "  X, Y = X[:-1000], Y[:-1000]\n",
        "  Yvalid_flat = np.argmax(Yvalid, axis=1) # for calculating error rate\n",
        "  \n",
        "  #print(\"X.shape:\", X.shape[0])\n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[0.2745098  0.31372549 0.32156863 ... 0.20392157 0.16862745\n",
            "    0.16078431]\n",
            "   [0.25490196 0.23921569 0.22745098 ... 0.21960784 0.20392157\n",
            "    0.17254902]\n",
            "   [0.19607843 0.16862745 0.21176471 ... 0.19215686 0.21960784\n",
            "    0.18431373]\n",
            "   ...\n",
            "   [0.35686275 0.25490196 0.16470588 ... 0.28235294 0.21960784\n",
            "    0.16862745]\n",
            "   [0.30196078 0.32156863 0.30980392 ... 0.41176471 0.2745098\n",
            "    0.18039216]\n",
            "   [0.30196078 0.28235294 0.32941176 ... 0.41568627 0.42745098\n",
            "    0.32156863]]]\n",
            "\n",
            "\n",
            " [[[0.59215686 0.58823529 0.57647059 ... 0.50588235 0.54901961\n",
            "    0.47058824]\n",
            "   [0.59215686 0.58431373 0.58431373 ... 0.47843137 0.55294118\n",
            "    0.5372549 ]\n",
            "   [0.59215686 0.59215686 0.61176471 ... 0.42745098 0.48235294\n",
            "    0.57254902]\n",
            "   ...\n",
            "   [0.7372549  0.7372549  0.4745098  ... 0.7254902  0.7254902\n",
            "    0.72941176]\n",
            "   [0.7372549  0.73333333 0.76862745 ... 0.72941176 0.71372549\n",
            "    0.73333333]\n",
            "   [0.72941176 0.72156863 0.7254902  ... 0.75686275 0.71764706\n",
            "    0.72156863]]]\n",
            "\n",
            "\n",
            " [[[0.90588235 0.83137255 0.61176471 ... 0.17254902 0.10588235\n",
            "    0.0627451 ]\n",
            "   [0.89803922 0.68627451 0.58039216 ... 0.10588235 0.1372549\n",
            "    0.10588235]\n",
            "   [0.83921569 0.61176471 0.61568627 ... 0.10980392 0.08627451\n",
            "    0.10980392]\n",
            "   ...\n",
            "   [0.94509804 0.96078431 0.98039216 ... 0.22352941 0.39607843\n",
            "    0.57254902]\n",
            "   [0.96470588 0.98039216 0.98823529 ... 0.30588235 0.41176471\n",
            "    0.63529412]\n",
            "   [0.98039216 0.98431373 0.98039216 ... 0.34509804 0.43137255\n",
            "    0.59607843]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[0.22745098 0.3254902  0.38039216 ... 0.1254902  0.08627451\n",
            "    0.09019608]\n",
            "   [0.28235294 0.36470588 0.39607843 ... 0.11764706 0.09803922\n",
            "    0.09019608]\n",
            "   [0.34117647 0.38431373 0.40392157 ... 0.10196078 0.11372549\n",
            "    0.10588235]\n",
            "   ...\n",
            "   [0.22745098 0.22745098 0.18431373 ... 0.63921569 0.50588235\n",
            "    0.12941176]\n",
            "   [0.23137255 0.23529412 0.18039216 ... 0.59215686 0.23921569\n",
            "    0.05098039]\n",
            "   [0.23137255 0.22745098 0.19607843 ... 0.38431373 0.0745098\n",
            "    0.07058824]]]\n",
            "\n",
            "\n",
            " [[[0.22745098 0.3254902  0.38039216 ... 0.1254902  0.08627451\n",
            "    0.09019608]\n",
            "   [0.28235294 0.36470588 0.39607843 ... 0.11764706 0.09803922\n",
            "    0.09019608]\n",
            "   [0.34117647 0.38431373 0.40392157 ... 0.10196078 0.11372549\n",
            "    0.10588235]\n",
            "   ...\n",
            "   [0.22745098 0.22745098 0.18431373 ... 0.63921569 0.50588235\n",
            "    0.12941176]\n",
            "   [0.23137255 0.23529412 0.18039216 ... 0.59215686 0.23921569\n",
            "    0.05098039]\n",
            "   [0.23137255 0.22745098 0.19607843 ... 0.38431373 0.0745098\n",
            "    0.07058824]]]\n",
            "\n",
            "\n",
            " [[[0.22745098 0.3254902  0.38039216 ... 0.1254902  0.08627451\n",
            "    0.09019608]\n",
            "   [0.28235294 0.36470588 0.39607843 ... 0.11764706 0.09803922\n",
            "    0.09019608]\n",
            "   [0.34117647 0.38431373 0.40392157 ... 0.10196078 0.11372549\n",
            "    0.10588235]\n",
            "   ...\n",
            "   [0.22745098 0.22745098 0.18431373 ... 0.63921569 0.50588235\n",
            "    0.12941176]\n",
            "   [0.23137255 0.23529412 0.18039216 ... 0.59215686 0.23921569\n",
            "    0.05098039]\n",
            "   [0.23137255 0.22745098 0.19607843 ... 0.38431373 0.0745098\n",
            "    0.07058824]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Es1KtZRdh-LZ",
        "colab_type": "code",
        "outputId": "e4ff3291-ffe5-48f7-ec37-848a9bd0cc09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1496
        }
      },
      "source": [
        "#create the model\n",
        "# https://github.com/nhduong/fer2013/blob/master/fer2013.ipynb\n",
        "from tensorflow.python.keras.optimizers import Adam\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dropout, Flatten, Dense, Activation\n",
        "from tensorflow.python.keras.layers import  Conv2D, MaxPooling2D\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping\n",
        "from tensorflow.python.keras.regularizers import l1, l2\n",
        "from keras.callbacks import History \n",
        "\n",
        "n_inputs = 2304\n",
        "n_classes = 7\n",
        "img_dim = 48\n",
        "model = Sequential()\n",
        "history = History()\n",
        "#model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape = (48, 48, 1)))\n",
        "#model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#model.add(Dropout(0.25))\n",
        "\n",
        "#model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "#model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "#model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "#model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "\n",
        "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#model.add(Dropout(0.25))\n",
        "\n",
        "#model.add(Conv2D(96, (3, 3), activation='relu', padding='same', input_shape = (48, 48, 1)))\n",
        "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#model.add(Conv2D(384, (3, 3), activation='relu'))\n",
        "#model.add(Conv2D(384, (3, 3), activation='relu'))\n",
        "#model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(8, (3, 3), activation='relu', padding='same', input_shape = (48, 48, 1)))\n",
        "model.add(Conv2D(8, (3, 3), activation='relu'))\n",
        "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1024, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(n_classes, activation='softmax'))\n",
        "\n",
        "opt = Adam(lr=0.0001, decay=10e-6)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "batch_size = 128\n",
        "n_epoches = 100\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "hist = model.fit(X, Y, batch_size=batch_size, epochs=n_epoches,\n",
        "          validation_data=(Xvalid, Yvalid), shuffle=True,\n",
        "          callbacks=[early_stopping])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 39263 samples, validate on 1000 samples\n",
            "Epoch 1/100\n",
            "39263/39263 [==============================] - 17s 434us/sample - loss: 2.5964 - acc: 0.2234 - val_loss: 2.2505 - val_acc: 0.2020\n",
            "Epoch 2/100\n",
            "39263/39263 [==============================] - 16s 407us/sample - loss: 2.0983 - acc: 0.2234 - val_loss: 2.0156 - val_acc: 0.1980\n",
            "Epoch 3/100\n",
            "39263/39263 [==============================] - 16s 400us/sample - loss: 1.8631 - acc: 0.2981 - val_loss: 1.7625 - val_acc: 0.3520\n",
            "Epoch 4/100\n",
            "39263/39263 [==============================] - 16s 398us/sample - loss: 1.6858 - acc: 0.3812 - val_loss: 1.6320 - val_acc: 0.3750\n",
            "Epoch 5/100\n",
            "39263/39263 [==============================] - 16s 396us/sample - loss: 1.5836 - acc: 0.4214 - val_loss: 1.5332 - val_acc: 0.4320\n",
            "Epoch 6/100\n",
            "39263/39263 [==============================] - 16s 397us/sample - loss: 1.4985 - acc: 0.4514 - val_loss: 1.4700 - val_acc: 0.4530\n",
            "Epoch 7/100\n",
            "39263/39263 [==============================] - 16s 411us/sample - loss: 1.4290 - acc: 0.4740 - val_loss: 1.3966 - val_acc: 0.4880\n",
            "Epoch 8/100\n",
            "39263/39263 [==============================] - 16s 399us/sample - loss: 1.3585 - acc: 0.4970 - val_loss: 1.3474 - val_acc: 0.4980\n",
            "Epoch 9/100\n",
            "39263/39263 [==============================] - 16s 410us/sample - loss: 1.3101 - acc: 0.5167 - val_loss: 1.3213 - val_acc: 0.5150\n",
            "Epoch 10/100\n",
            "39263/39263 [==============================] - 16s 410us/sample - loss: 1.2699 - acc: 0.5287 - val_loss: 1.2884 - val_acc: 0.5130\n",
            "Epoch 11/100\n",
            "39263/39263 [==============================] - 16s 404us/sample - loss: 1.2317 - acc: 0.5440 - val_loss: 1.2408 - val_acc: 0.5310\n",
            "Epoch 12/100\n",
            "39263/39263 [==============================] - 16s 396us/sample - loss: 1.2093 - acc: 0.5498 - val_loss: 1.2358 - val_acc: 0.5260\n",
            "Epoch 13/100\n",
            "39263/39263 [==============================] - 16s 402us/sample - loss: 1.1813 - acc: 0.5581 - val_loss: 1.2553 - val_acc: 0.5290\n",
            "Epoch 14/100\n",
            "39263/39263 [==============================] - 16s 407us/sample - loss: 1.1630 - acc: 0.5659 - val_loss: 1.2248 - val_acc: 0.5260\n",
            "Epoch 15/100\n",
            "39263/39263 [==============================] - 16s 399us/sample - loss: 1.1405 - acc: 0.5766 - val_loss: 1.2379 - val_acc: 0.5240\n",
            "Epoch 16/100\n",
            "39263/39263 [==============================] - 16s 409us/sample - loss: 1.1244 - acc: 0.5823 - val_loss: 1.2083 - val_acc: 0.5270\n",
            "Epoch 17/100\n",
            "39263/39263 [==============================] - 16s 407us/sample - loss: 1.1059 - acc: 0.5884 - val_loss: 1.1934 - val_acc: 0.5510\n",
            "Epoch 18/100\n",
            "39263/39263 [==============================] - 15s 392us/sample - loss: 1.0915 - acc: 0.5935 - val_loss: 1.1930 - val_acc: 0.5460\n",
            "Epoch 19/100\n",
            "39263/39263 [==============================] - 16s 410us/sample - loss: 1.0800 - acc: 0.6007 - val_loss: 1.1958 - val_acc: 0.5420\n",
            "Epoch 20/100\n",
            "39263/39263 [==============================] - 16s 408us/sample - loss: 1.0572 - acc: 0.6098 - val_loss: 1.1794 - val_acc: 0.5460\n",
            "Epoch 21/100\n",
            "39263/39263 [==============================] - 16s 396us/sample - loss: 1.0424 - acc: 0.6155 - val_loss: 1.1742 - val_acc: 0.5530\n",
            "Epoch 22/100\n",
            "39263/39263 [==============================] - 16s 407us/sample - loss: 1.0305 - acc: 0.6217 - val_loss: 1.1734 - val_acc: 0.5500\n",
            "Epoch 23/100\n",
            "39263/39263 [==============================] - 16s 410us/sample - loss: 1.0161 - acc: 0.6272 - val_loss: 1.1635 - val_acc: 0.5620\n",
            "Epoch 24/100\n",
            "39263/39263 [==============================] - 16s 395us/sample - loss: 1.0009 - acc: 0.6339 - val_loss: 1.1914 - val_acc: 0.5470\n",
            "Epoch 25/100\n",
            "39263/39263 [==============================] - 16s 397us/sample - loss: 0.9874 - acc: 0.6392 - val_loss: 1.1822 - val_acc: 0.5560\n",
            "Epoch 26/100\n",
            "39263/39263 [==============================] - 16s 400us/sample - loss: 0.9721 - acc: 0.6458 - val_loss: 1.1807 - val_acc: 0.5590\n",
            "Epoch 27/100\n",
            "39263/39263 [==============================] - 16s 411us/sample - loss: 0.9529 - acc: 0.6533 - val_loss: 1.1994 - val_acc: 0.5630\n",
            "Epoch 28/100\n",
            "39263/39263 [==============================] - 16s 405us/sample - loss: 0.9368 - acc: 0.6620 - val_loss: 1.2033 - val_acc: 0.5520\n",
            "Epoch 29/100\n",
            "39263/39263 [==============================] - 15s 392us/sample - loss: 0.9261 - acc: 0.6654 - val_loss: 1.2005 - val_acc: 0.5700\n",
            "Epoch 30/100\n",
            "39263/39263 [==============================] - 16s 401us/sample - loss: 0.9081 - acc: 0.6724 - val_loss: 1.1952 - val_acc: 0.5560\n",
            "Epoch 31/100\n",
            "39263/39263 [==============================] - 16s 413us/sample - loss: 0.8949 - acc: 0.6816 - val_loss: 1.1841 - val_acc: 0.5590\n",
            "Epoch 32/100\n",
            "39263/39263 [==============================] - 16s 410us/sample - loss: 0.8788 - acc: 0.6845 - val_loss: 1.2242 - val_acc: 0.5640\n",
            "Epoch 33/100\n",
            "39263/39263 [==============================] - 16s 402us/sample - loss: 0.8597 - acc: 0.6930 - val_loss: 1.2137 - val_acc: 0.5800\n",
            "Epoch 34/100\n",
            "39263/39263 [==============================] - 16s 406us/sample - loss: 0.8487 - acc: 0.6975 - val_loss: 1.2584 - val_acc: 0.5560\n",
            "Epoch 35/100\n",
            "39263/39263 [==============================] - 16s 398us/sample - loss: 0.8287 - acc: 0.7060 - val_loss: 1.2278 - val_acc: 0.5630\n",
            "Epoch 36/100\n",
            "39263/39263 [==============================] - 16s 409us/sample - loss: 0.8189 - acc: 0.7128 - val_loss: 1.3115 - val_acc: 0.5470\n",
            "Epoch 37/100\n",
            "39263/39263 [==============================] - 16s 406us/sample - loss: 0.7961 - acc: 0.7198 - val_loss: 1.2595 - val_acc: 0.5650\n",
            "Epoch 38/100\n",
            "39263/39263 [==============================] - 16s 402us/sample - loss: 0.7819 - acc: 0.7241 - val_loss: 1.2764 - val_acc: 0.5580\n",
            "Epoch 39/100\n",
            "39263/39263 [==============================] - 16s 407us/sample - loss: 0.7706 - acc: 0.7288 - val_loss: 1.2637 - val_acc: 0.5720\n",
            "Epoch 40/100\n",
            "39263/39263 [==============================] - 16s 407us/sample - loss: 0.7463 - acc: 0.7382 - val_loss: 1.3076 - val_acc: 0.5710\n",
            "Epoch 41/100\n",
            "39263/39263 [==============================] - 16s 397us/sample - loss: 0.7352 - acc: 0.7440 - val_loss: 1.3255 - val_acc: 0.5730\n",
            "Epoch 42/100\n",
            "39263/39263 [==============================] - 16s 396us/sample - loss: 0.7241 - acc: 0.7495 - val_loss: 1.3272 - val_acc: 0.5670\n",
            "Epoch 43/100\n",
            "39263/39263 [==============================] - 16s 403us/sample - loss: 0.6992 - acc: 0.7614 - val_loss: 1.3619 - val_acc: 0.5720\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoNVl3mSpWOP",
        "colab_type": "code",
        "outputId": "535cf4d5-fa95-4d9b-9771-dfbbc0e8606e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "# evaluate the model\n",
        "scores = model.evaluate(Xvalid, Yvalid)\n",
        "print('%s: %.2f%%'% (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "model.save('fer2013_3.h5')\n",
        "model.save_weights('fer2013_weights_3.h5')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 0s 332us/sample - loss: 1.3619 - acc: 0.5720\n",
            "acc: 57.20%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gu9gKOkm3SQR",
        "colab_type": "code",
        "outputId": "6fdbea44-9f31-4a54-b42f-8f344dd6f391",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# load training model\n",
        "\n",
        "model.load_weights('fer2013_weights_3.h5')\n",
        "\n",
        "scores = model.evaluate(Xvalid, Yvalid)\n",
        "print('%s: %.2f%%'% (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 0s 446us/sample - loss: 1.6811 - acc: 0.6660\n",
            "acc: 66.60%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C0bbswJ4zx1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_emotion(ohv):\n",
        "    if ohv.shape[0] == 1:\n",
        "        indx = ohv[0]\n",
        "    else:\n",
        "        indx = np.argmax(ohv)\n",
        "        \n",
        "    if indx == 0:\n",
        "        return 'angry'\n",
        "    elif indx == 1:\n",
        "        return 'disgust'\n",
        "    elif indx == 2:\n",
        "        return 'fear'\n",
        "    elif indx == 3:\n",
        "        return 'happy'\n",
        "    elif indx == 4:\n",
        "        return 'sad'\n",
        "    elif indx == 5:\n",
        "        return 'surprise'\n",
        "    elif indx == 6:\n",
        "        return 'neutral'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lrs_9HQ3qS8",
        "colab_type": "code",
        "outputId": "53b8f358-35c6-4a70-cfc5-db73ae56e5ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "# test model\n",
        "import matplotlib.pyplot as plt\n",
        "img_index=20\n",
        "sample = Xvalid[img_index, :]\n",
        "sample = sample.reshape(48, 48)\n",
        "\n",
        "\n",
        "pred_cls = model.predict_classes(sample.reshape(1, 48, 48, 1))\n",
        "\n",
        "plt.imshow(sample, cmap='gray')\n",
        "plt.show()\n",
        "print('> testing image index: %d\\n> true emotion: %s\\n> predicted emotion: %s' % (img_index, get_emotion(Yvalid[img_index, :]), get_emotion(pred_cls)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFLCAYAAABft66eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEQfqLEVEHKizFBFxoM5SRMTB/wHtoDTYktvB4gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "> testing image index: 20\n",
            "> true emotion: angry\n",
            "> predicted emotion: angry\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}